{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----- make nice figures -----\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['figure.dpi']= 300\n",
    "from cycler import cycler\n",
    "COLORS = ['#F00D2C', '#242482', '#0071BE', '#4E8F00', '#553C67', '#DA5319']\n",
    "default_cycler = cycler(color=COLORS)\n",
    "plt.rc('axes', prop_cycle=default_cycler) \n",
    "# -----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mu_theta = 700\n",
    "sigma_theta = 50\n",
    "\n",
    "# Calculate pdf values for prior distribution\n",
    "theta = np.linspace(500, 900, 200)\n",
    "f_prior = norm.pdf(theta, loc = mu_theta, scale = sigma_theta)\n",
    "\n",
    "# Plot prior pdf\n",
    "plt.plot(theta, f_prior, linewidth=3)\n",
    "plt.grid()\n",
    "plt.title('Prior distribution on Theta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data_file_name = \"data/JAHANMI2.txt\"\n",
    "data = np.loadtxt(data_file_name, skiprows=1)\n",
    "\n",
    "# Extract strength column\n",
    "X = data[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First observation:\n",
    "x_obs = X[0]\n",
    "\n",
    "# We'll calculate the unnormalized posterior (without normalization factors)\n",
    "f_posterior = np.exp( -(x_obs - theta)**2/(2*10**2) ) * np.exp(-(theta-700)**2/(2*50**2))\n",
    "\n",
    "plt.plot(theta, f_posterior, linewidth=3)\n",
    "plt.grid()\n",
    "plt.title('Unnormalized Posterior Distribution on Theta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Update for Normal-Normal Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig = 10\n",
    "a = 700\n",
    "b = 50\n",
    "\n",
    "# This is the closed form solution for the bayesian update for the Normal-Normal model\n",
    "a_posterior = (sig**2*a + b**2*x_obs) / (sig**2 + b**2)\n",
    "b_posterior = np.sqrt((sig**2*b**2) / (sig**2 + b**2))\n",
    "\n",
    "y = norm.pdf(theta, loc = a_posterior, scale = b_posterior)\n",
    "plt.plot(theta, y, linewidth=3)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Impact on uncertainties on posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\sigma^2_\\Theta$ small, $\\sigma^2_X$ small\n",
    "\n",
    "In this case, we are very confident in our data measurement (if we were to get more data, the values wouldn't change much from what we know). We're also confident in our prior estimate of the mean of the data distribution. We'll assume a true data distribution of $X \\sim \\mathcal N(\\Theta, 1^2)$ with unknown mean $\\Theta$. \n",
    "\n",
    "We'll assume a prior distribution on this parameter $\\Theta \\sim \\mathcal N(8, 1^2)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "sig_X = 1\n",
    "\n",
    "# Our prior distribution on Theta\n",
    "mu_Theta = 8\n",
    "sig_Theta = 1\n",
    "\n",
    "# Plot the prior distrion\n",
    "theta = np.linspace(0, 20, 100)\n",
    "pdf_vals = norm.pdf(theta, mu_Theta, sig_Theta)\n",
    "\n",
    "plt.plot(theta, pdf_vals)\n",
    "plt.grid()\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Prior Distribution on Θ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we observe x = 10. How does our posterior look like based on this new information? We can use the update formula for the Normal-Normal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = 10\n",
    "\n",
    "hat_mu_Theta = (sig_X**2*mu_Theta + sig_Theta**2*x_obs) / (sig_X**2 + sig_Theta**2)\n",
    "hat_sig_Theta = np.sqrt((sig_X**2 * sig_Theta**2) / (sig_X**2 + sig_Theta**2))\n",
    "\n",
    "# Now evaluate the normal pdf with these posterior parameter values\n",
    "posterior_pdf_vals = norm.pdf(theta, hat_mu_Theta, hat_sig_Theta)\n",
    "plt.plot(theta, pdf_vals)\n",
    "plt.plot(theta, posterior_pdf_vals)\n",
    "plt.grid()\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Prior and Posterior Distribution on Θ')\n",
    "\n",
    "plt.legend(['Prior', 'Posterior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of this posterior is $\\hat \\mu_\\Theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hat_mu_Theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_obs = 20\n",
    "\n",
    "hat_mu_Theta = (sig_X**2*mu_Theta + sig_Theta**2*x_obs) / (sig_X**2 + sig_Theta**2)\n",
    "hat_sig_Theta = np.sqrt((sig_X**2 * sig_Theta**2) / (sig_X**2 + sig_Theta**2))\n",
    "\n",
    "# Now evaluate the normal pdf with these posterior parameter values\n",
    "posterior_pdf_vals = norm.pdf(theta, hat_mu_Theta, hat_sig_Theta)\n",
    "plt.plot(theta, pdf_vals)\n",
    "plt.plot(theta, posterior_pdf_vals)\n",
    "plt.grid()\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Prior and Posterior Distribution on Θ')\n",
    "\n",
    "plt.legend(['Prior', 'Posterior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of this posterior is $\\hat \\mu_\\Theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hat_mu_Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $\\Theta$ here represents the mean of the data distribution. We initially thought the data had mean 8 ($\\pm 1$), and we then observed data with value 20. The resulting updated estimate is 14, which is exactly between 8 and 20!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\sigma^2_\\Theta$ small, $\\sigma^2_X$ large\n",
    "\n",
    "Let's do the same thing, but lets assume the data comes from a wider distribution. In other words, we have less \"certainty\" that any one observed value $X$ is close to the average value that before. Let's assume \n",
    "\n",
    "$$ X \\sim \\mathcal N(\\Theta, 3^2) $$.\n",
    "\n",
    "We'll still assume a prior distribution on $\\Theta \\sim \\mathcal N(8, 1)$. Now what happens when we observe $x = 20$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_X = 3\n",
    "\n",
    "# Our prior distribution on Theta\n",
    "mu_Theta = 8\n",
    "sig_Theta = 1\n",
    "\n",
    "x_obs = 20\n",
    "\n",
    "hat_mu_Theta = (sig_X**2*mu_Theta + sig_Theta**2*x_obs) / (sig_X**2 + sig_Theta**2)\n",
    "hat_sig_Theta = np.sqrt((sig_X**2 * sig_Theta**2) / (sig_X**2 + sig_Theta**2))\n",
    "\n",
    "# Now evaluate the normal pdf with these posterior parameter values\n",
    "pdf_vals = norm.pdf(theta, mu_Theta, sig_Theta)\n",
    "posterior_pdf_vals = norm.pdf(theta, hat_mu_Theta, hat_sig_Theta)\n",
    "plt.plot(theta, pdf_vals)\n",
    "plt.plot(theta, posterior_pdf_vals)\n",
    "plt.grid()\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Prior and Posterior Distribution on Θ')\n",
    "\n",
    "plt.legend(['Prior', 'Posterior'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean of this posterior is $\\hat \\mu_\\Theta$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hat_mu_Theta)\n",
    "print(mu_Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the posterior mean is still between the observed value and the prior mean, but it is much closer to the prior value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\sigma^2_\\Theta$ large, $\\sigma^2_X$ small\n",
    "\n",
    "In this case, we are not so confident in our initial estimate of the parameter $\\Theta$, but we are confident in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_X = 1\n",
    "\n",
    "# Our prior distribution on Theta\n",
    "mu_Theta = 8\n",
    "sig_Theta = 3\n",
    "\n",
    "x_obs = 20\n",
    "\n",
    "hat_mu_Theta = (sig_X**2*mu_Theta + sig_Theta**2*x_obs) / (sig_X**2 + sig_Theta**2)\n",
    "hat_sig_Theta = np.sqrt((sig_X**2 * sig_Theta**2) / (sig_X**2 + sig_Theta**2))\n",
    "\n",
    "# Now evaluate the normal pdf with these posterior parameter values\n",
    "pdf_vals = norm.pdf(theta, mu_Theta, sig_Theta)\n",
    "posterior_pdf_vals = norm.pdf(theta, hat_mu_Theta, hat_sig_Theta)\n",
    "plt.plot(theta, pdf_vals)\n",
    "plt.plot(theta, posterior_pdf_vals)\n",
    "plt.grid()\n",
    "plt.xlabel('θ')\n",
    "plt.ylabel('Probability Density')\n",
    "plt.title('Prior and Posterior Distribution on Θ')\n",
    "\n",
    "plt.legend(['Prior', 'Posterior'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hat_mu_Theta)\n",
    "print(mu_Theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, the posterior estimate of the average data valuer is much closer to the observed value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
